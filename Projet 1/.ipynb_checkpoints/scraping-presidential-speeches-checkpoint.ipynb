{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this code\n",
    "The purpose of this notebook is to show an example of how we can extract information from web pages with some level of accuracy.\n",
    "I've made this notebook as an example to help you in case you needed to scrape infromation in the future.\n",
    "Here, we are collecting the speeches of previous presidents of the united states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files structures\n",
    "The folders exist each named by the name of some of the american presidents\n",
    "inside each folder, there is an html file \"initial.txt\" scraped from millercenter.org\n",
    "containing links for all the speeches of each corresponding president"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.stdout.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc9 in position 555: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-15ca3f172e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# open the \"initial.txt\" file for each president\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhtml_links_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_links_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# extract the speeches links from the <a> tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0;31m# It's a file-type object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         elif len(markup) <= 256 and (\n\u001b[1;32m    288\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34mb'<'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc9 in position 555: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# parent folder\n",
    "path = 'presidents-speeches/'\n",
    "\n",
    "# will contain all the data \"president name\" : [\"speeches links\"]\n",
    "presidential_dictionary_list = []\n",
    "for (root, dirs, files) in walk(path):\n",
    "    # go through child folders, skip the first parent folder\n",
    "    if len(dirs) == 1:\n",
    "        president_speahces_dict = {}\n",
    "        # get the name of the president from the file path\n",
    "        president_name = root.split(\"/\")[1]\n",
    "        president_speahces_dict['president_name'] = president_name\n",
    "        speches_links = []\n",
    "        file_path = \"{}/{}\".format(root,files[0])\n",
    "        # open the \"initial.txt\" file for each president\n",
    "        with open(file_path) as html_links_file:\n",
    "            if(not file_path.endswith('DS_Store')):\n",
    "                soup = BeautifulSoup(html_links_file)\n",
    "                for link in soup.findAll('a'):\n",
    "                    # extract the speeches links from the <a> tags\n",
    "                    speches_links.append(link.get('href'))\n",
    "            president_speahces_dict['speeches_links'] = speches_links\n",
    "            presidential_dictionary_list.append(president_speahces_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_dictionary_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch speeches from the site\n",
    "now that we have the links of the speeches, we can fetch them and extract the content\n",
    "we will save them in files titled by date__title, corresponding to every president"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format speech titles to be appropriate for usage as file names\n",
    "import re\n",
    "def file_name_format(text):\n",
    "    return re.sub('[^A-Za-z0-9\\-\\_]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for presidential_dictionary in presidential_dictionary_list:\n",
    "    print(\"extracting speeches of president {}\".format(presidential_dictionary['president_name']))\n",
    "    speech_counter = 1\n",
    "    total_speeches = len(presidential_dictionary['speeches_links'])\n",
    "    for speech_link in presidential_dictionary['speeches_links']:\n",
    "        try:\n",
    "            resp = requests.get(\"https://millercenter.org/{}\".format(speech_link))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "        print(\"speech {}/{}\".format(speech_counter,total_speeches))\n",
    "        speech_counter+=1\n",
    "        if resp.status_code == 200:\n",
    "            soup = BeautifulSoup(resp._content)\n",
    "            print(soup)\n",
    "            president_speech = ''\n",
    "            # the speech is present inside a <div> with class \"view-transcript\", as a set of <p> tags\n",
    "            for transcripts in soup.find_all('div', { \"class\" : \"view-transcript\"}):# there is only one view-transcript per page\n",
    "                ps = transcripts.find_all('p')\n",
    "                president_speech = ' '.join([p.text for p in ps])\n",
    "            # get the title and date of every speech, and name the file accordingly\n",
    "            for title in soup.find_all('h2', { \"class\" : \"presidential-speeches--title\"}):\n",
    "                ttl = title.find('span').text\n",
    "                date_speech_title = ttl.split(\":\")\n",
    "                date = date_speech_title[0].strip()\n",
    "                speech_title = date_speech_title[1].strip()\n",
    "            with open(path+presidential_dictionary['president_name']+\"/speeches/\"+date+\"__\"+file_name_format(speech_title)+\".txt\",\"w+\") as out_file:\n",
    "                out_file.write(str(president_speech.encode('utf8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin\n",
    "After running this code, all the speeches are be saved inside their corresponding president folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
