{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('news.txt','r').read()\n",
    "sentences = sent_tokenize(text)\n",
    "total_documents = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "transformed = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'british': 20, 'airways': 10, 'budget': 21, 'rival': 80, 'ryanair': 81, 'cancelled': 23, 'hundreds': 54, 'flights': 47, 'demand': 35, 'travel': 91, 'drops': 38, 'amid': 11, 'fears': 43, 'spread': 88, 'coronavirus': 28, 'ba': 14, 'cancelling': 24, '216': 3, '16': 0, '28': 5, 'march': 63, 'london': 61, 'destinations': 36, 'including': 55, 'new': 67, 'york': 96, 'italy': 57, 'france': 51, 'austria': 13, 'belgium': 15, 'germany': 52, 'ireland': 56, 'cut': 31, '25': 4, '17': 1, 'april': 12, 'tourists': 90, 'business': 22, 'people': 73, 'cutting': 32, 'foreign': 49, 'significant': 87, 'expansion': 42, 'number': 69, 'cases': 26, 'uk': 92, 'prime': 74, 'minister': 66, 'boris': 18, 'johnson': 58, 'warned': 93, 'boss': 19, 'michael': 64, 'leary': 60, 'said': 82, 'focus': 48, 'time': 89, 'minimising': 65, 'risk': 79, 'passengers': 72, 'heavily': 53, 'booked': 16, 'weeks': 94, 'notable': 68, 'drop': 37, 'forward': 50, 'bookings': 17, 'end': 40, 'early': 39, 'makes': 62, 'sense': 86, 'selectively': 85, 'prune': 75, 'schedule': 84, 'airports': 9, 'affected': 8, 'covid': 29, '19': 2, 'outbreak': 71, 'firm': 45, 'declined': 34, 'say': 83, 'affect': 7, 'results': 78, 'financial': 44, 'year': 95, 'ends': 41, '31': 6, 'contact': 27, 'customers': 30, 'offer': 70, 'rebooking': 76, 'carriers': 25, 'refunds': 77, 'flight': 46, 'later': 59, 'date': 33}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['british', 'airways', 'budget', 'rival', 'ryanair']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.vocabulary_.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "tfidf_transformer=TfidfTransformer(use_idf=True)\n",
    "tfidf_transformer.fit(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airways',\n",
       " 'amid',\n",
       " 'april',\n",
       " 'austria',\n",
       " 'ba',\n",
       " 'belgium',\n",
       " 'booked',\n",
       " 'bookings',\n",
       " 'boris',\n",
       " 'boss']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you only needs to do this once, this is a mapping of index to \n",
    "feature_names=vectorizer.get_feature_names()\n",
    "feature_names[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(matrix):\n",
    "    tuples = zip(matrix.col, matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence\n",
      "British Airways and budget rival Ryanair have cancelled hundreds of flights as demand for travel drops amid fears about the spread of coronavirus.\n",
      "Keywords\n",
      "spread 0.304\n",
      "rival 0.304\n",
      "hundreds 0.304\n",
      "fears 0.304\n",
      "drops 0.304\n",
      "demand 0.304\n",
      "budget 0.304\n",
      "amid 0.304\n",
      "coronavirus 0.222\n",
      "cancelled 0.222\n"
     ]
    }
   ],
   "source": [
    "sent=sentences[0]\n",
    " \n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(vectorizer.transform([sent]))\n",
    " \n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items = sort(tf_idf_vector.tocoo())\n",
    " \n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    " \n",
    "# now print the results\n",
    "print(\"sentence\")\n",
    "print(sent)\n",
    "print(\"Keywords\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
